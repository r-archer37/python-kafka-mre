# This file sets up the minimum number of containers required to connect confluent-kafka to test connections through ssl
version: '2'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:5.3.1
    ports:
      - "2181:2181"
    mem_limit: 512m
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - test-net-1
  kafka:
    image: confluentinc/cp-kafka:5.3.1
    ports:
      - "9092:9092"
    restart: always
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: SSL://kafka:9092
      KAFKA_SSL_KEYSTORE_FILENAME: server.keystore.jks
      KAFKA_SSL_KEYSTORE_CREDENTIALS: credfile
      KAFKA_SSL_KEY_CREDENTIALS: credfile
      KAFKA_SSL_TRUSTSTORE_FILENAME: server.truststore.jks
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS: credfile
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: " "
      KAFKA_SSL_CLIENT_AUTH: required
      KAFKA_SECURITY_INTER_BROKER_PROTOCOL: SSL
      # By setting these protocols differently between python and Kafka, you can force a name resolution error
      KAFKA_SSL_ENABLED_PROTOCOLS: TLSv1.2 # e.g., TLSv1.1, TLSv1.2
      # By setting one particular cipher as the only enabled, you can force a no-cipher-suites-in-common error
#       KAFKA_SSL_ENABLED_CIPHERS: 50331807
#      KAFKA_LOG4J_ROOT_LOGLEVEL: DEBUG
#      KAFKA_TOOLS_LOG4J_LOGLEVEL: DEBUG
      KAFKA_CREATE_TOPICS: "my_topic:1:1"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
#       KAFKA_INTER_BROKER_PROTOCOL_VERSION: 0.11.0
    volumes:
      - .:/etc/kafka/secrets
    networks:
      - test-net-1
    mem_limit: 1G
  python36test:
    image: jupyter/tensorflow-notebook:be289da10d60
    volumes:
    - .:/home/jovyan
    depends_on:
    - kafka
    networks:
      - test-net-1
    command: ["bash","mre_startup.sh"]

networks:
  test-net-1:
